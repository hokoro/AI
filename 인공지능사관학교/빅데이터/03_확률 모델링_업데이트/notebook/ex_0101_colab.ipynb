{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ex_0101_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIW3riCwi1FM"
      },
      "source": [
        "### n-Gram 언어 모델 응용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaQsRWdMi1FP"
      },
      "source": [
        "import nltk\n",
        "from numpy.random import randint, seed\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrYwBvyHi1FQ"
      },
      "source": [
        "# 다음을 한번 실행한다!\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz2o_A77i1FR"
      },
      "source": [
        "# Train을 위한 데이터.\n",
        "my_text = \"\"\"Machine learning is the scientific study of algorithms and statistical models that computer systems use to effectively perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.[1][2]:2 Machine learning algorithms are used in the applications of email filtering, detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory data analysis through unsupervised learning In its application across business problems, machine learning is also referred to as predictive analytics.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7CHfH1ii1FR"
      },
      "source": [
        "my_text = [my_text.lower()]                       # 소문자로 저장. CountVectorizer() 요구대로 리스트로 정리."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3izZmQEi1FS"
      },
      "source": [
        "#### 1. n-Gram 시험적 실행."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVlS1kPvi1FS"
      },
      "source": [
        "n = 3                                                           # 2 이상의 정수로 변경 가능.\n",
        "n_min = n\n",
        "n_max = n\n",
        "n_gram_type = 'word'                                             # 단어 단위의 n-Gram. \n",
        "my_vectorizer = CountVectorizer(ngram_range=(n_min,n_max), analyzer = n_gram_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad36KsXki1FT"
      },
      "source": [
        "n_grams = my_vectorizer.fit(my_text).get_feature_names()         # n-Gram을 리스트로.  \n",
        "n_gram_cts = my_vectorizer.transform(my_text).toarray()          # 결과는 array of array.\n",
        "n_gram_cts = list(n_gram_cts[0])                                 # 단순한 리스트로 변환."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QQt8Xp-i1FU"
      },
      "source": [
        "n_gram_zipped = list(zip(n_grams,n_gram_cts))                                    # 튜플로 이루어진 리스트로 변환.\n",
        "n_gram_zipped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CClPNobmi1FU"
      },
      "source": [
        "n_grams = []\n",
        "for n_gram, ct in n_gram_zipped:\n",
        "    n_grams.extend([n_gram]*ct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjUieSZvi1FV"
      },
      "source": [
        "n_grams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-Qdiouoi1FV"
      },
      "source": [
        "#### 2. 학습: n-Gram을 key로 하는 딕셔너리 만들기. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dty49kri1FV"
      },
      "source": [
        "n = 3                                                           # 2 이상의 정수로 변경 가능.\n",
        "n_min = n                              \n",
        "n_max = n                              \n",
        "n_gram_type = 'word'\n",
        "my_vectorizer = CountVectorizer(ngram_range=(n_min,n_max), analyzer = n_gram_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5wsMxqMi1FW"
      },
      "source": [
        "n_grams = my_vectorizer.fit(my_text).get_feature_names()         # n-Gram을 리스트로.  \n",
        "n_gram_cts = my_vectorizer.transform(my_text).toarray()          # 결과는 array of array.\n",
        "n_gram_cts = list(n_gram_cts[0])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwUm-qAbi1FW"
      },
      "source": [
        "n_gram_zipped = list(zip(n_grams,n_gram_cts))                                    # 튜플로 이루어진 리스트로 변환.\n",
        "n_gram_zipped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORBekKSni1FW"
      },
      "source": [
        "n_grams = []\n",
        "for n_gram, ct in n_gram_zipped:\n",
        "    n_grams.extend([n_gram]*ct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBtTbioBi1FW"
      },
      "source": [
        "my_dict = {}\n",
        "for a_gram in n_grams:\n",
        "    words = nltk.word_tokenize(a_gram)\n",
        "    a_nm1_gram = ' '.join(words[0:n-1])                         # (n-1)-Gram.\n",
        "    next_word = words[-1]                                       # a_nm1_gram 이후의 단어\n",
        "    if a_nm1_gram not in my_dict.keys():\n",
        "        my_dict[a_nm1_gram] = [next_word]                       # a_nm1_gram은 새로운 key. 딕셔너리에 처음 입력.\n",
        "    else:\n",
        "        my_dict[a_nm1_gram] += [next_word]                      # an_nm1_gram은 이미 딕셔너리에 있는 key."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzD7IotXi1FW"
      },
      "source": [
        "# 딕셔너리 내용을 본다.\n",
        "my_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnQEVpx_i1FX"
      },
      "source": [
        "#### 3. 다음 단어 예측."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSCYEtZHi1FX"
      },
      "source": [
        "# 헬퍼 함수.\n",
        "def predict_next(a_nm1_gram):\n",
        "    value_list_size = len(my_dict[a_nm1_gram])         # key = a_nm1_gram에 해당하는 value의 크기.\n",
        "    i_pick = randint(0, value_list_size)               # 0 ~ value_list_size 중 하나 랜덤으로 선택.\n",
        "    return(my_dict[a_nm1_gram][i_pick])                  # 랜덤으로 선택된 다음 단어 반환."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lgIgsbii1FX"
      },
      "source": [
        "# 테스트.\n",
        "input_str = 'study of'                                 # 실제로 존재하는 (n-1)-Gram을 입력한다!\n",
        "predict_next(input_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2kJgqHji1FX"
      },
      "source": [
        "# 다시 한번 테스트.\n",
        "# 이어서 예측을 10번 반복한다. \n",
        "input_str = 'machine learning'                                 # 실제로 존재하는 (n-1)-Gram을 입력한다!\n",
        "for i in range(10):\n",
        "    print(predict_next(input_str))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX4K0Eewi1FX"
      },
      "source": [
        "#### 4. 문자열 예측."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls3GTSW0i1FY"
      },
      "source": [
        "# 랜덤 시드 초기화.\n",
        "seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UBr3fqni1FY"
      },
      "source": [
        "# 사용자 입력 시드 문자열.\n",
        "#my_seed_str = 'machine learning'                                   # 실제로 존재하는 (n-1)-Gram을 입력한다!\n",
        "my_seed_str = 'in order'                                         # 실제로 존재하는 (n-1)-Gram을 입력한다!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kotpRdeVi1FY"
      },
      "source": [
        "a_nm1_gram = my_seed_str\n",
        "output_string = my_seed_str                                         # 출력 문자열 초기화.\n",
        "while a_nm1_gram in my_dict:\n",
        "    output_string += \" \" + predict_next(a_nm1_gram)\n",
        "    words = nltk.word_tokenize(output_string)\n",
        "    a_nm1_gram = ' '.join(words[-n+1:])                            # a_nm1_gram 갱신."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEXmF91Vi1FY"
      },
      "source": [
        "# 예측된 문자열 출력.\n",
        "output_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5QS5VIqi1FY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}