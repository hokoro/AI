{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"이미지증폭.ipynb","provenance":[],"authorship_tag":"ABX9TyNEGrYmPw1Zem/Kjgpqs77/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"j7mYL9HvCDQc"},"source":["#%%\n","\n","from flower_init import *\n","\n","#%%\n","\n","xs,ys = flowers_init([100, 100])\n","\n","#%%\n","\n","#이미지 증폭 라이브러리\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","#%%\n","\n","#데이터 증폭의 옵션을 결정하는 객체 선언\n","image_generator = ImageDataGenerator(rotation_range=30,\n","                                     zoom_range = 0.7,\n","                                     shear_range=0.75,\n","                                     width_shift_range=0.45,\n","                                     height_shift_range=0.45,\n","                                     horizontal_flip=True,\n","                                     vertical_flip=True)\n","\n","#%% md\n","'''\n","이미지 데이터의 정규화 과정\n","왜 정규화 할때 MinMaxScaler 를 사용할 것인가요?\n","'''\n","#%%\n","\n","#\n","image_generator.flow()\n","\n","\n","#%%\n","\n","#정규화\n","xs_norm = xs - 0 / (255.0 -0)\n","\n","#%%\n","\n","import numpy as np\n","#shuffle\n","shuffle_map = np.arange(xs_norm.shape[0])\n","np.random.shuffle((shuffle_map))\n","\n","#%%\n","\n","train_ratio = 0.8\n","\n","test_begin_index = int(xs_norm.shape[0] * train_ratio)\n","\n","train_x = xs_norm[shuffle_map[:test_begin_index]]\n","test_x = xs_norm[shuffle_map[test_begin_index:]]\n","\n","\n","train_y = ys[shuffle_map[:test_begin_index]]\n","test_y= ys[shuffle_map[test_begin_index:]]\n","\n","#%%\n","\n","#하나의 데이터를 100장 증폭 과정\n","train_x[0].shape\n","\n","#%%\n","\n","augment_size = 100\n","#flow 이미지 데이터 증폭 함수\n","#정석: np.tile(1차원 데이터를 받음) 실제 : np.tile(3차원 데이터가 들어감\n","x_augment = image_generator.flow(x = np.tile(train_x[0].reshape(100,100,3),reps = augment_size ).reshape(-1,100,100,3),\n","                                 y = np.zeros(augment_size),\n","                                 batch_size=augment_size,\n","                                 shuffle = False #데이터 증폭시 중복을 허용할거냐 False = 안함\n","                                 ).next()[0] #증폭된 종속변수 만 가져 올수 있다.\n","#증폭된 종속 변수만 가져올때는 .next()[0]\n","#증폭할떄 몇번 반복해야 하는지도 x에 전달 시켜줘야함\n","#np.tile A = tile 의 대상 /\n","\n","#%%\n","\n","x_augment.shape\n","\n","#%%\n","\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(30,30))\n","for i in range(100):\n","    plt.subplot(10,10,i+1)\n","    plt.axis('off')\n","    i = np.random.choice(100, replace = False)\n","    plt.imshow(x_augment[i])\n","plt.show()\n","\n","#%%\n","\n","#1.노이즈 증폭 / 2.GAN 을 사용\n","# 원본 데이터 증폭 시켜주기 train_x\n","#원본 데이터 의 50 % 만 해당하는 복제본 생성 한 후에 복사 데이터를 증폭 시켜주는 과정 수행\n","\n","agument_size = int(train_x.shape[0] * 0.5) #절반만 증폭\n","\n","print(agument_size)\n","\n","#%%\n","\n","#복사본 데이터 생성 과정\n","x_choice = np.random.choice(train_x.shape[0],size = augment_size,replace=False)\n","#중복 허용을 금지하고  train_x 의 절반의 데이터 만 가져온다\n","\n","x_augmented = train_x[x_choice].copy() #랜덤의 받아온 index 를 copy 하여 저장\n","x_augmented.shape\n","\n","y_augmented = train_y[x_choice].copy()\n","y_augmented.shape\n","\n","#%%\n","\n","#노이즈를 포함하여 증폭 시킨 x 의 독립변수 데이터\n","x_augmented = image_generator.flow(x_augmented,\n","                                   np.zeros(augment_size),\n","                                   batch_size=augment_size,\n","                                   shuffle= False).next()[0] #독립변수의 증폭값만 가져옴\n","\n","#%%\n","\n","plt.figure(figsize=(30,30))\n","for i in range(100):\n","    plt.subplot(10,10,i+1)\n","    plt.axis('off')\n","    i = np.random.choice(100, replace = False)\n","    plt.imshow(x_augment[i])\n","plt.show()\n","\n","#%%\n","\n","#원본데이터 trainx,y 랑 증폭을 시킨 데이터를 합쳐주기 concatenate\n","train_x = np.concatenate((train_x,x_augmented))\n","train_y = np.concatenate((train_y,y_augmented))\n","\n","#%%\n","\n","## 전의 학습\n","#학습된 layer 만 가져와서 우리의 데이터로 학습하는 방식 출력계층은 다시 재정의 해서 만든다.\n","#학습이 되어진 데이터를 가져오지만 학습을 더시켜야 한다. 이미 학습이 완료한 계층을 학습을 시키지 않고 Freeze 를 수행한다.\n","#내가 지금 가지고 있는데이터는 가져온 모델이랑 안맞는게 당연하다 이때 일부만 freeze 를 해체 하여 학습을 더 시킬수 있다.\n","#데이터의 크기에따라 얼려지는 데이터의 양이 다 다르다.\n","\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.applications import VGG19\n","from tensorflow.keras.applications import Xception\n","from tensorflow.keras.applications import MobileNetV2\n","\n","#%%\n","\n","mobile_v2= MobileNetV2()\n","\n","mobile_v2.summary()\n","\n","#data 를 받기 2가지\n","#1그냥 링크 다고 다운 받기\n","\n","#%%\n","\n","import tensorflow as tf\n","tf.keras.utils.get_file('/content/labels.csv','http://bit.ly/2GDxsYS')\n","tf.keras.utils.get_file('/content/train.zip','http://bit.ly/31nIyel')\n","tf.keras.utils.get_file('/content/test.zip','http://bit.ly/2GHEsnO')\n","\n","\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2 #openCV -> pip install opencv-python / pip install cv2\n","import os\n","import csv\n","\n","from PIL import Image\n","\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.layers import Input\n","\n","mobile_v2 = MobileNetV2()\n","mobile_v2.summary()\n","\n","label_text = pd.read_csv('dog-breed-identification/labels.csv')\n","\n","#견종의 수가 얼마나 되는지 확인\n","label_text['bread'].nunique() #120 가지의 견종의 내용이 있음\n","\n","\n","#이미지와 견종의 정보에 대한 출력\n","\n","# 사진당 크기\n","plt.figure(figsize=(20,20))\n","\n","# 총 16장의 사진을 출력\n","for i in range(16):\n","\n","    # 가로 4개 세로 4개씩 하여 이미지를 출력합니다.\n","    plt.subplot(4,4,i+1)\n","\n","    # 무작위 값을 주어 매번 다른 이미지가 출력되도록 합니다.\n","    i = np.random.choice(1000)\n","\n","    #label_text 변수에 loc를 사용하여\n","    # [i번 째 행,'id' 라는 열] 의 값을 할당합니다.\n","    image_id = label_text.loc[i, 'id']\n","\n","    #절대경로 설정을 활용하여 사진 출력\n","    # 이미지\n","    plt.imshow(plt.imread('dataset/dogs/train/train/' + image_id + '.jpg'))\n","\n","    #사진과 함께 번호(i) + 제목 ( loc[i,'breed'] ) 출력\n","    plt.title(str(i) + '-' + label_text.loc[i, 'breed'])\n","\n","    # 축 정보 표기 x\n","    plt.axis('off')\n","\n","plt.show()\n","\n","#전의 학습을 위한 두가지 실험\n","#1.가지고온 신경망의 모든 계층을 초기화  다시 학습을 시키는 과정 (학습 x -> 시간과 성능이 구림)\n","#2.가지고 온 신경망의 절반의 계층을 초기화 하고 학습을 시킨다 (학습 o)\n","\n","#첫번째 실험\n","mobile_net_v2 = MobileNetV2()\n","mobile_net_v2.summary()\n","\n","for layer in mobile_net_v2.layers[:,-1]:\n","    layer.trainable = True #traindata 를 학습 가능한 데이터로 만들수있다.\n","\n","\n","for layer in mobile_net_v2[:-1]:\n","    if 'kernel ' in layer.__dict__:\n","\n","        kernel_shape = np.array(layer.get_weights()).shape\n","        layer.set_weights(np.random.normal(0,1,kernel_shape))\n","\n","#1.독립변수를 생성해 주는 과정\n","#2. 같은 크기로 모든 이미지를 만들어주는 과정\n","#3. a모든 이미지를 minmax 할 과정\n","\n","\n","# 독립변수를 생성해 주는 과정\n","# 1. 모든 이미지를 같은 크기로 만들어 주는 과정\n","# 2. 모든 이미지를 min-max 시켜주는 과정\n","\n","\n","train_X = [] # 전처리를 마친 변수를 받는 빈 리스트 변수\n","\n","# 모든 이미지의 수를 확인하고 반복문 활용\n","for i in range(len(label_text)):\n","\n","    # 이미지 읽어들이기 (이미지 저장 경로를 확인해주세요.)\n","    img = cv2.imread('dataset/dogs/train/train/' + label_text['id'][i] + '.jpg')\n","    img = cv2.resize(img, dsize = (224,224)) #이미지 크기 통일\n","\n","    # 이미지 정규화 과정\n","    img = img / 255.0 (min-max norm)\n","\n","    train_x = append(img)\n","\n","train_x = np.array(train_X)\n","\n","print(train_x.shape)\n","\n","\n","#종속변수 생성 과정\n","unique_y = label_text['breed'].unique().tolist()\n","\n","train_y = [unique_y.index(breed) for breed in label_text['bread']]\n","train_y = np.array(train_y)\n","#마지막 이전 계층\n","output_layer_2 = mobile_v2.layers[-2]\n","\n","#신경망 출력계층의  None , 120\n","prediction = tf.keras.layers.Dense(units = 120,activation = 'softmax')(output_layer_2)\n","\n","#input = 입력계층 , outputs = 출력 계층\n","model = tf.keras.Model(inputs = mobile_v2 ,outputs = prediction ) #가운데 은닉계층은 tf가 잡아온다 / but tf 가 어떻게 해주냐?\n","#그래서 함수형 방식은 마지막 계층이 어디에 위치하는지 알려줘야한다 즉 연결 시켜줘야 한다.\n","model.summary()\n","\n","#compile 과정\n","\n","model.compile(optimizers = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])\n","\n","#텐서보드 를 위한 log 폴더 생성 과정\n","os.makedirs('/imageamp/log')\n","\n","log_dir = '/imageamp/log'\n","\n","#학습을 위한 코드\n","history = model.fit(train_x,train_y , epochs = 10 ,validation_split = 0.25,batch_size = 32,callbacks = [tf.keras.callbacks.EarlyStopping(patience = 5) , tf.keras.callbacks.TensorBoard(log_dir = log_dir)])\n","\n","\n","#두번쨰 실험 : 절반의 계층 만 사용한다  freeze 방식\n","\n","from tensorflow.keras.applications import MobileNetV2\n","import tensorflow as tf\n","\n","mobilev2        = MobileNetV2()\n","output_layer_2  = mobilev2.layers[-2].output\n","predictions     = tf.keras.layers.Dense(120, activation='softmax')(output_layer_2)\n","\n","model = tf.keras.Model(inputs=mobilev2.input, outputs=predictions)\n","model.summary()\n","\n","#신경망 계층의 절반만 학습을 시키기 위한 코드\n","for layer in model.layers[:-20]:\n","    layer.trainable = False #처음 부터 중간 20 번쨰 계층 까지 를 학습 을 안시키기 위한 설정\n","\n","\n","for layer in model.layers[-20:]:\n","    layer.trainable = True #20번쨰 부터 마지막 번쨰 계층 까지 를 학습 을 시키기 위한 설정\n","\n","\n","\n","model.compile(optimizers = 'sgd',\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])\n","\n","\n","history = model.fit(train_x,train_y , epochs = 10 ,validation_split = 0.25,batch_size = 32,callbacks = [tf.keras.callbacks.EarlyStopping(patience = 5) , tf.keras.callbacks.TensorBoard(log_dir = log_dir)])\n","\n","#tensorboard 사용 방법\n","'''\n","1.아나콘다 프롬프트 에 실행 \n","2.현재 사용중인 가상 환경으로 이동한다.\n","conda activate '이름'\n"," \n","3. 가상 환경에서 텐서보드 실행 코드\n","### tensorboard --logdir=C 드라이브 의 경로 \n","### 여기서 log 파일까지의 경로는 여러분들의 경로로 잡아주시면 됩니다. \n","\n","4. 하단의 출력 되어진 localhost 를 복사 하여 웹에 붙여 넣어 준다.\n","'''\n","\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['loss'], 'b-', label='loss')\n","plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n","plt.xlabel('Epoch')\n","\n","plt.legend()\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n","plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()\n","model = tf.keras.models.load_model('save_model/ImageNet_dogs.h5')\n","\n","img = plt.imread('dataset/dogs/test/test/001510bc8570bbeee98c8d80c8a95ec1.jpg')\n","img = np.resize(img,(224,224,3))\n","img = img / 255.0\n","img = np.expand_dims(img, axis=0)\n","\n","prob = model.predict(img)\n","\n","\n","print(\"Predict Prob : \\n\",np.round(prob * 100,1))\n","plt.imshow(plt.imread('dataset/dogs/test/test/001510bc8570bbeee98c8d80c8a95ec1.jpg'))\n","print(\"Model Predict : Index-{}\".format(np.argmax(prob)))"],"execution_count":null,"outputs":[]}]}