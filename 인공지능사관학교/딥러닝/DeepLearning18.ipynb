{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepLearning18.ipynb","provenance":[],"authorship_tag":"ABX9TyOl40daCyGWwseFtO/0klz+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BNN3AncWycjm"},"source":["#데이터 증폭 버전 이진분류 학습 "]},{"cell_type":"code","metadata":{"id":"Zr14ls_XQzi_","executionInfo":{"status":"ok","timestamp":1629015751117,"user_tz":-540,"elapsed":466,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["%run /content/MathUtils.ipynb\n","%run /content/abalone_model.ipynb"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ke5vTNqA2t3_","executionInfo":{"status":"ok","timestamp":1629015751609,"user_tz":-540,"elapsed":7,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def binary_classification_exec(epoch_count = 10, mb_size = 10, report = 1, train_ratio = 0.6, val_ratio = 0.2, adjust_ratio = False):\n","    binary_load_dataset(adjust_ratio)\n","    init_param()\n","    train_metrics_mean_row, val_metrics_row, test_metrics = train_and_test(epoch_count, mb_size, report, train_ratio, val_ratio)\n","\n","    return train_metrics_mean_row, val_metrics_row, test_metrics"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"bhB_UpAY2v7w","executionInfo":{"status":"ok","timestamp":1629015751609,"user_tz":-540,"elapsed":7,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def binary_load_dataset(adjust_ratio):\n","\n","    pulsars, stars = [], []\n","\n","    with open('/content/pulsar_stars.csv') as csvfile:\n","\n","        csvreader = csv.reader(csvfile)\n","        next(csvreader)\n","\n","        for row in csvreader:\n","            if row[8] == '1' : pulsars.append(row)\n","\n","            else:\n","                stars.append(row)\n","\n","    global data, input_cnt, output_cnt\n","    input_cnt, output_cnt = 8, 1\n","\n","    star_cnt, pulsar_cnt = len(stars), len(pulsars)\n","\n","    # 증폭 과정 수행 \n","    if adjust_ratio:\n","        data = np.zeros([ star_cnt * 2 , 9])\n","        data[0 : star_cnt, : ] = np.asarray(stars, dtype='float32')\n","        \n","        for n in range(star_cnt):\n","            data[star_cnt + n] = np.asarray(pulsars[n % pulsar_cnt], dtype='float32')\n","\n","    # 증폭 과정 수행 X\n","    else:\n","        data = np.zeros([ star_cnt + pulsar_cnt ,  9])\n","        data[0 : star_cnt, : ] = np.asarray(stars, dtype='float32')\n","        data[star_cnt : , :  ] = np.asarray(pulsars, dtype='float32')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"4fAPkqAZ3yPr","executionInfo":{"status":"ok","timestamp":1629015751610,"user_tz":-540,"elapsed":7,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def init_param():\n","    global weight, bias \n","\n","    # 기능 축소 \n","#    weight_initial = []\n","#    bias_initial   = []\n","\n","    # input_cnt = 8 , output_cnt = 1\n","    weight = np.random.normal(RND_MEAN, RND_STD, size = [input_cnt, output_cnt])\n","    bias   = np.zeros([output_cnt])\n","    print(\"Initial Weight Value : \\n{}\".format(weight))\n","    print(\"Initial Bias Value : \\n{}\".format(bias))\n","\n","#    weight_initial.append(weight)\n","#    bias_initial.append(bias)\n","\n","#    return weight_initial, bias_initial"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"aMmflzUC4zGd","executionInfo":{"status":"ok","timestamp":1629015751610,"user_tz":-540,"elapsed":7,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def safe_div(p, q):\n","    p, q = float(p), float(q)\n","    if np.abs(q) < 1.0e-20:\n","        return np.sign(p)\n","    return p / q"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKZGkj1W40i7","executionInfo":{"status":"ok","timestamp":1629015751610,"user_tz":-540,"elapsed":5,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def eval_accuracy_numpy(output,y):\n","\n","    # 예측값을 0과 비교하여 줍니다. \n","    # 예측값을 0과 비교하는 이유는 시그모이드 활성화 함수의 특징인데, \n","    # 입력값이 음수인 경우는 출력값이 0.5 보다 작으니 0으로, \n","    # 입력값이 양수인 경우는 출력값이 0.5 보다 크니 1로 판단할 수 있습니다.\n","\n","    est_yes = np.greater(output,0)\n","    ans_yes = np.greater(y, 0.5)\n","\n","    est_no = np.logical_not(est_yes) \n","    ans_no = np.logical_not(ans_yes)\n","\n","\n","    # 마찬가지로 평가에 사용된 결과를 모두 더해 \n","    # 각각의 혼동행렬을 만들어 줍니다.  \n","    tp = np.sum(np.logical_and(est_yes, ans_yes))\n","    tn = np.sum(np.logical_and(est_no, ans_no))\n","    fp = np.sum(np.logical_and(ans_no, est_yes))\n","    fn = np.sum(np.logical_and(ans_yes, est_no))\n","\n","    # 다음은 정확도 측정 지표를 만들어 줍니다. \n","    # 이때 나눗셈의 경우 0으로 나눠지는 경우가 \n","    # 발생할 수 있기에, \n","    # 이 점을 고려하여 안전한 나눗셈 함수를 만들어 주겠습니다. \n","    accuracy = safe_div(tp+tn,tp+fp+fn+tn)\n","    precision = safe_div(tp,tp+fp)\n","    recall = safe_div(tp,tp+fn)\n","    f1 = 2 * safe_div(recall*precision,recall+precision)\n","    \n","    return [accuracy, precision, recall, f1]"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2uSwiL2429o","executionInfo":{"status":"ok","timestamp":1629015752144,"user_tz":-540,"elapsed":538,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def train_and_test(epoch_count, mb_size, report, train_ratio, val_ratio):\n","\n","    mini_batch_step_count = arrange_data(mb_size,train_ratio, val_ratio)\n","\n","    test_x, test_y = get_test_data()\n","    val_x,  val_y  = get_val_data()\n","\n","    losses_mean_row = []\n","    val_loss_row    = []\n","\n","    #losses_mean_row, accs_mean_row = [], []\n","    #val_loss_row, val_acc_row      = [], []\n","    \n","    for epoch in range(epoch_count):\n","\n","        losses = []\n","        #accs = []\n","\n","        for n in range(mini_batch_step_count):\n","            train_x, train_y  = get_train_data(mb_size, n)\n","           \n","            loss, _           = run_train(train_x,train_y)\n","               \n","            losses.append(loss)\n","            #accs.append(acc)\n","\n","        val_loss, val_acc = run_test(val_x, val_y)\n","        val_loss_row.append(val_loss)\n","        #val_acc_row.append(val_acc)  \n","\n","        if report > 0 and (epoch+1) % report == 0:\n","            \n","            print(\"Epoch {} : Train - Loss = {:.3f} / Val - Loss = {:.3f}, Acc = {:.3f}, Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3F}\".\\\n","                  format(epoch+1, np.mean(losses), val_loss, val_acc[0], val_acc[1], val_acc[2], val_acc[3]))\n","            \n","        losses_mean = np.mean(losses) \n","        #accs_mean = np.mean(accs)\n","\n","        losses_mean_row.append(losses_mean)  \n","        #accs_mean_row.append(accs_mean)   \n","\n","\n","\n","    test_loss, test_acc = run_test(test_x, test_y)\n","    \n","    print(\"\\n\",\"=\" * 50, 'Final Test', '=' * 50)\n","    print('\\nTest Acc = {:.3f}, Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3F}'.\\\n","          format(test_acc[0], test_acc[1], test_acc[2], test_acc[3]))\n","    print('\\nLoss = {:.3f}'.format(test_loss))\n","\n","    #return [losses_mean_row, accs_mean_row], [val_loss_row, val_acc_row], [test_loss , test_acc]\n","    return [losses_mean_row], [val_loss_row], [test_loss , test_acc]"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"8H4VCmg545O8","executionInfo":{"status":"ok","timestamp":1629015752144,"user_tz":-540,"elapsed":18,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def run_train(x, y):\n","    y_hat, aux_nn_x           = forward_neuralnet(x)\n","    loss, aux_pp_y_output_CEE = forward_postproc(y_hat, y)\n","\n","    accuracy = eval_accuracy_numpy(y_hat, y)\n","\n","    G_output = backprop_postproc(aux_pp_y_output_CEE)\n","    backprop_neuralnet(G_output, aux_nn_x)\n","\n","    return loss, accuracy"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Pu7ZBn14568","executionInfo":{"status":"ok","timestamp":1629015752145,"user_tz":-540,"elapsed":19,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def run_test(x, y):\n","    y_hat, _ = forward_neuralnet(x)\n","    loss, _  = forward_postproc(y_hat, y)\n","    accuracy = eval_accuracy_numpy(y_hat, y)\n","\n","    return loss, accuracy"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoQLY6a25eyw","executionInfo":{"status":"ok","timestamp":1629015752145,"user_tz":-540,"elapsed":18,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def arrange_data(mb_size, train_ratio, val_ratio):\n","    \n","    global shuffle_map, test_begin_index, val_begin_index\n","\n","    shuffle_map = np.arange(data.shape[0])\n","    np.random.shuffle(shuffle_map)\n","\n","    mini_batch_step_count = int(data.shape[0] * train_ratio) // mb_size\n","\n","    val_begin_index  = mini_batch_step_count * mb_size\n","    test_begin_index = int(val_begin_index + (val_ratio * data.shape[0])) \n","\n","\n","    return mini_batch_step_count"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0dwA9wU5gm1","executionInfo":{"status":"ok","timestamp":1629015752146,"user_tz":-540,"elapsed":18,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def get_train_data(mb_size, n):\n","    # 기능 축소 \n","    #if n == 0:\n","    #    np.random.shuffle(shuffle_map[:test_begin_index])\n","    \n","    # n 값은 미니배치의 수  \n","    from_idx = mb_size * n\n","    to_idx   = mb_size * (n+1)\n","\n","    train_data = data[shuffle_map[from_idx : to_idx ]]\n","\n","    return train_data[ : , : -output_cnt], train_data[ : , -output_cnt : ]\n","\n","def get_test_data():\n","    test_data = data[shuffle_map[test_begin_index:]]\n","    return test_data[ : , : -output_cnt], test_data[ : , -output_cnt : ]\n","\n","def get_val_data():\n","    val_data = data[shuffle_map[ val_begin_index : test_begin_index ]]\n","    return val_data[ : , : -output_cnt], val_data[ : , -output_cnt : ]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_F5d6p25kS-","executionInfo":{"status":"ok","timestamp":1629015752146,"user_tz":-540,"elapsed":18,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def forward_neuralnet(x):\n","    y_hat = np.matmul(x, weight) + bias\n","    return y_hat, x"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Osd1Gv-n5lbA","executionInfo":{"status":"ok","timestamp":1629015752146,"user_tz":-540,"elapsed":17,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def relu(x):\n","    return np.maximum(x, 0)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pxue4UZR5mcs","executionInfo":{"status":"ok","timestamp":1629015752147,"user_tz":-540,"elapsed":17,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["# z 값 실제 y값, x값은 신경망의 예측값\n","def sigmoid_cross_entropy_with_logits(z, x):\n","    \n","    return relu(x) - x * z + np.log(1+np.exp(-np.abs(x)))"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rh46qA0S5nw7","executionInfo":{"status":"ok","timestamp":1629015752147,"user_tz":-540,"elapsed":16,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def forward_postproc(output, y):\n","    CEE  = sigmoid_cross_entropy_with_logits(y, output)\n","    loss = np.mean(CEE)\n","\n","    return loss, [y, output, CEE]"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"xW1PfU0a5pus","executionInfo":{"status":"ok","timestamp":1629015752147,"user_tz":-540,"elapsed":15,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def backprop_neuralnet(G_output, x):\n","    global weight, bias \n","\n","    x_transpose = x.transpose()\n","    G_w = np.matmul(x_transpose, G_output)\n","    \n","    G_b = np.sum(G_output, axis = 0)\n","\n","    weight -= LEARNING_RATE * G_w\n","    bias   -= LEARNING_RATE * G_b"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwXWiM-i5rEQ","executionInfo":{"status":"ok","timestamp":1629015752147,"user_tz":-540,"elapsed":13,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def sigmoid_cross_entropy_with_logits_derv(z, x):\n","    return -z + sigmoid(x)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"dAFTCPSl5sP2","executionInfo":{"status":"ok","timestamp":1629015752148,"user_tz":-540,"elapsed":13,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def sigmoid(x):\n","    return np.exp(-relu(-x)) / (1.0 + np.exp(-np.abs(x)))"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7lPH5Qo5tSF","executionInfo":{"status":"ok","timestamp":1629015752148,"user_tz":-540,"elapsed":13,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":["def backprop_postproc(aux_pp_y_output_CEE):\n","\n","    y, output, CEE = aux_pp_y_output_CEE\n","\n","    g_loss_entropy   = 1.0 / np.prod(CEE.shape)\n","    g_entropy_output = sigmoid_cross_entropy_with_logits_derv(y, output)\n","\n","    G_output = g_entropy_output * g_loss_entropy \n","\n","    return G_output\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPoGr3lR5uxf","executionInfo":{"status":"ok","timestamp":1629015752148,"user_tz":-540,"elapsed":12,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}}},"source":[""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5z6xFfz5bgC","executionInfo":{"status":"ok","timestamp":1629015759230,"user_tz":-540,"elapsed":7093,"user":{"displayName":"천영성","photoUrl":"","userId":"06905110897473075189"}},"outputId":"efe5c956-0497-468b-bd75-433c8d1a1a6b"},"source":["train_metrics_mean_row, val_metrics_row, test_metrics = binary_classification_exec(epoch_count = 100, \n","                                                                                   mb_size     = 32, \n","                                                                                   report      = 1, \n","                                                                                   train_ratio = 0.6, \n","                                                                                   val_ratio   = 0.2)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Initial Weight Value : \n","[[-0.04428074]\n"," [-0.0130573 ]\n"," [-0.00272253]\n"," [ 0.01814162]\n"," [ 0.0417707 ]\n"," [-0.00399044]\n"," [ 0.00591716]\n"," [-0.01894233]]\n","Initial Bias Value : \n","[0.]\n","Epoch 1 : Train - Loss = 8.248 / Val - Loss = 34.593, Acc = 0.927, Precision = 1.000, Recall = 0.237, F1 = 0.383\n","Epoch 2 : Train - Loss = 5.935 / Val - Loss = 2.285, Acc = 0.974, Precision = 0.946, Recall = 0.775, F1 = 0.852\n","Epoch 3 : Train - Loss = 5.737 / Val - Loss = 16.499, Acc = 0.947, Precision = 0.994, Recall = 0.447, F1 = 0.617\n","Epoch 4 : Train - Loss = 4.695 / Val - Loss = 16.783, Acc = 0.944, Precision = 1.000, Recall = 0.418, F1 = 0.590\n","Epoch 5 : Train - Loss = 4.671 / Val - Loss = 4.693, Acc = 0.968, Precision = 0.868, Recall = 0.789, F1 = 0.827\n","Epoch 6 : Train - Loss = 5.395 / Val - Loss = 22.159, Acc = 0.941, Precision = 1.000, Recall = 0.386, F1 = 0.557\n","Epoch 7 : Train - Loss = 5.070 / Val - Loss = 28.312, Acc = 0.938, Precision = 1.000, Recall = 0.354, F1 = 0.523\n","Epoch 8 : Train - Loss = 4.968 / Val - Loss = 10.137, Acc = 0.959, Precision = 0.990, Recall = 0.579, F1 = 0.731\n","Epoch 9 : Train - Loss = 4.874 / Val - Loss = 36.647, Acc = 0.935, Precision = 1.000, Recall = 0.316, F1 = 0.480\n","Epoch 10 : Train - Loss = 5.696 / Val - Loss = 2.579, Acc = 0.975, Precision = 0.963, Recall = 0.766, F1 = 0.853\n","Epoch 11 : Train - Loss = 5.192 / Val - Loss = 2.573, Acc = 0.972, Precision = 0.869, Recall = 0.833, F1 = 0.851\n","Epoch 12 : Train - Loss = 4.964 / Val - Loss = 34.622, Acc = 0.935, Precision = 1.000, Recall = 0.325, F1 = 0.490\n","Epoch 13 : Train - Loss = 5.253 / Val - Loss = 34.648, Acc = 0.936, Precision = 1.000, Recall = 0.330, F1 = 0.497\n","Epoch 14 : Train - Loss = 5.379 / Val - Loss = 8.056, Acc = 0.963, Precision = 0.991, Recall = 0.614, F1 = 0.758\n","Epoch 15 : Train - Loss = 4.287 / Val - Loss = 35.596, Acc = 0.935, Precision = 1.000, Recall = 0.322, F1 = 0.487\n","Epoch 16 : Train - Loss = 5.164 / Val - Loss = 1.704, Acc = 0.974, Precision = 0.917, Recall = 0.804, F1 = 0.857\n","Epoch 17 : Train - Loss = 5.753 / Val - Loss = 3.029, Acc = 0.973, Precision = 0.973, Recall = 0.740, F1 = 0.841\n","Epoch 18 : Train - Loss = 6.015 / Val - Loss = 1.937, Acc = 0.976, Precision = 0.941, Recall = 0.795, F1 = 0.862\n","Epoch 19 : Train - Loss = 7.358 / Val - Loss = 2.833, Acc = 0.972, Precision = 0.866, Recall = 0.833, F1 = 0.849\n","Epoch 20 : Train - Loss = 4.762 / Val - Loss = 3.769, Acc = 0.971, Precision = 0.984, Recall = 0.711, F1 = 0.825\n","Epoch 21 : Train - Loss = 6.198 / Val - Loss = 5.009, Acc = 0.969, Precision = 0.991, Recall = 0.678, F1 = 0.806\n","Epoch 22 : Train - Loss = 4.596 / Val - Loss = 2.490, Acc = 0.975, Precision = 0.963, Recall = 0.769, F1 = 0.855\n","Epoch 23 : Train - Loss = 5.962 / Val - Loss = 4.999, Acc = 0.968, Precision = 0.991, Recall = 0.675, F1 = 0.803\n","Epoch 24 : Train - Loss = 4.642 / Val - Loss = 14.498, Acc = 0.954, Precision = 1.000, Recall = 0.515, F1 = 0.680\n","Epoch 25 : Train - Loss = 4.325 / Val - Loss = 4.448, Acc = 0.974, Precision = 0.914, Recall = 0.804, F1 = 0.855\n","Epoch 26 : Train - Loss = 4.391 / Val - Loss = 5.526, Acc = 0.973, Precision = 0.949, Recall = 0.760, F1 = 0.844\n","Epoch 27 : Train - Loss = 4.256 / Val - Loss = 37.074, Acc = 0.935, Precision = 1.000, Recall = 0.325, F1 = 0.490\n","Epoch 28 : Train - Loss = 5.109 / Val - Loss = 2.631, Acc = 0.976, Precision = 0.967, Recall = 0.772, F1 = 0.859\n","Epoch 29 : Train - Loss = 5.840 / Val - Loss = 28.557, Acc = 0.941, Precision = 1.000, Recall = 0.386, F1 = 0.557\n","Epoch 30 : Train - Loss = 5.173 / Val - Loss = 11.349, Acc = 0.957, Precision = 0.990, Recall = 0.558, F1 = 0.714\n","Epoch 31 : Train - Loss = 4.682 / Val - Loss = 8.434, Acc = 0.963, Precision = 0.991, Recall = 0.620, F1 = 0.763\n","Epoch 32 : Train - Loss = 4.483 / Val - Loss = 4.835, Acc = 0.969, Precision = 0.992, Recall = 0.684, F1 = 0.810\n","Epoch 33 : Train - Loss = 4.456 / Val - Loss = 6.653, Acc = 0.966, Precision = 0.991, Recall = 0.652, F1 = 0.787\n","Epoch 34 : Train - Loss = 5.383 / Val - Loss = 34.908, Acc = 0.938, Precision = 1.000, Recall = 0.354, F1 = 0.523\n","Epoch 35 : Train - Loss = 5.221 / Val - Loss = 2.751, Acc = 0.974, Precision = 0.973, Recall = 0.749, F1 = 0.846\n","Epoch 36 : Train - Loss = 6.207 / Val - Loss = 4.024, Acc = 0.971, Precision = 0.980, Recall = 0.713, F1 = 0.826\n","Epoch 37 : Train - Loss = 6.062 / Val - Loss = 5.315, Acc = 0.969, Precision = 0.991, Recall = 0.681, F1 = 0.808\n","Epoch 38 : Train - Loss = 4.917 / Val - Loss = 5.085, Acc = 0.974, Precision = 0.946, Recall = 0.772, F1 = 0.850\n","Epoch 39 : Train - Loss = 4.977 / Val - Loss = 34.650, Acc = 0.939, Precision = 1.000, Recall = 0.357, F1 = 0.526\n","Epoch 40 : Train - Loss = 5.167 / Val - Loss = 4.259, Acc = 0.971, Precision = 0.988, Recall = 0.705, F1 = 0.823\n","Epoch 41 : Train - Loss = 5.423 / Val - Loss = 4.197, Acc = 0.971, Precision = 0.984, Recall = 0.705, F1 = 0.821\n","Epoch 42 : Train - Loss = 5.393 / Val - Loss = 32.265, Acc = 0.941, Precision = 1.000, Recall = 0.380, F1 = 0.551\n","Epoch 43 : Train - Loss = 5.386 / Val - Loss = 29.249, Acc = 0.942, Precision = 1.000, Recall = 0.392, F1 = 0.563\n","Epoch 44 : Train - Loss = 4.948 / Val - Loss = 4.303, Acc = 0.970, Precision = 0.984, Recall = 0.702, F1 = 0.819\n","Epoch 45 : Train - Loss = 5.746 / Val - Loss = 4.313, Acc = 0.970, Precision = 0.984, Recall = 0.702, F1 = 0.819\n","Epoch 46 : Train - Loss = 5.643 / Val - Loss = 2.419, Acc = 0.973, Precision = 0.949, Recall = 0.760, F1 = 0.844\n","Epoch 47 : Train - Loss = 4.410 / Val - Loss = 31.892, Acc = 0.940, Precision = 1.000, Recall = 0.374, F1 = 0.545\n","Epoch 48 : Train - Loss = 4.971 / Val - Loss = 8.277, Acc = 0.965, Precision = 0.991, Recall = 0.637, F1 = 0.776\n","Epoch 49 : Train - Loss = 4.171 / Val - Loss = 30.076, Acc = 0.942, Precision = 1.000, Recall = 0.392, F1 = 0.563\n","Epoch 50 : Train - Loss = 5.835 / Val - Loss = 4.941, Acc = 0.969, Precision = 0.987, Recall = 0.687, F1 = 0.810\n","Epoch 51 : Train - Loss = 4.984 / Val - Loss = 2.572, Acc = 0.976, Precision = 0.918, Recall = 0.822, F1 = 0.867\n","Epoch 52 : Train - Loss = 4.642 / Val - Loss = 2.565, Acc = 0.976, Precision = 0.913, Recall = 0.827, F1 = 0.868\n","Epoch 53 : Train - Loss = 5.547 / Val - Loss = 4.973, Acc = 0.969, Precision = 0.987, Recall = 0.681, F1 = 0.806\n","Epoch 54 : Train - Loss = 5.545 / Val - Loss = 2.059, Acc = 0.972, Precision = 0.851, Recall = 0.851, F1 = 0.851\n","Epoch 55 : Train - Loss = 4.863 / Val - Loss = 36.223, Acc = 0.937, Precision = 1.000, Recall = 0.339, F1 = 0.507\n","Epoch 56 : Train - Loss = 5.142 / Val - Loss = 35.439, Acc = 0.938, Precision = 1.000, Recall = 0.354, F1 = 0.523\n","Epoch 57 : Train - Loss = 4.967 / Val - Loss = 8.728, Acc = 0.964, Precision = 0.991, Recall = 0.626, F1 = 0.767\n","Epoch 58 : Train - Loss = 4.904 / Val - Loss = 4.183, Acc = 0.972, Precision = 0.984, Recall = 0.713, F1 = 0.827\n","Epoch 59 : Train - Loss = 5.559 / Val - Loss = 33.251, Acc = 0.939, Precision = 1.000, Recall = 0.363, F1 = 0.532\n","Epoch 60 : Train - Loss = 5.029 / Val - Loss = 4.216, Acc = 0.971, Precision = 0.984, Recall = 0.708, F1 = 0.823\n","Epoch 61 : Train - Loss = 5.605 / Val - Loss = 36.836, Acc = 0.938, Precision = 1.000, Recall = 0.354, F1 = 0.523\n","Epoch 62 : Train - Loss = 4.657 / Val - Loss = 2.076, Acc = 0.973, Precision = 0.878, Recall = 0.839, F1 = 0.858\n","Epoch 63 : Train - Loss = 5.893 / Val - Loss = 34.109, Acc = 0.940, Precision = 1.000, Recall = 0.368, F1 = 0.538\n","Epoch 64 : Train - Loss = 4.860 / Val - Loss = 24.519, Acc = 0.943, Precision = 1.000, Recall = 0.406, F1 = 0.578\n","Epoch 65 : Train - Loss = 5.098 / Val - Loss = 13.766, Acc = 0.955, Precision = 0.995, Recall = 0.529, F1 = 0.691\n","Epoch 66 : Train - Loss = 4.481 / Val - Loss = 34.774, Acc = 0.938, Precision = 1.000, Recall = 0.354, F1 = 0.523\n","Epoch 67 : Train - Loss = 4.564 / Val - Loss = 2.635, Acc = 0.969, Precision = 0.831, Recall = 0.848, F1 = 0.839\n","Epoch 68 : Train - Loss = 5.120 / Val - Loss = 4.162, Acc = 0.971, Precision = 0.984, Recall = 0.708, F1 = 0.823\n","Epoch 69 : Train - Loss = 5.680 / Val - Loss = 7.517, Acc = 0.966, Precision = 0.991, Recall = 0.652, F1 = 0.787\n","Epoch 70 : Train - Loss = 4.476 / Val - Loss = 4.204, Acc = 0.971, Precision = 0.984, Recall = 0.708, F1 = 0.823\n","Epoch 71 : Train - Loss = 5.711 / Val - Loss = 4.207, Acc = 0.972, Precision = 0.988, Recall = 0.711, F1 = 0.827\n","Epoch 72 : Train - Loss = 5.209 / Val - Loss = 2.758, Acc = 0.976, Precision = 0.967, Recall = 0.772, F1 = 0.859\n","Epoch 73 : Train - Loss = 5.396 / Val - Loss = 30.032, Acc = 0.942, Precision = 1.000, Recall = 0.389, F1 = 0.560\n","Epoch 74 : Train - Loss = 5.117 / Val - Loss = 4.090, Acc = 0.972, Precision = 0.984, Recall = 0.716, F1 = 0.829\n","Epoch 75 : Train - Loss = 5.883 / Val - Loss = 31.913, Acc = 0.941, Precision = 1.000, Recall = 0.383, F1 = 0.554\n","Epoch 76 : Train - Loss = 5.568 / Val - Loss = 3.903, Acc = 0.973, Precision = 0.980, Recall = 0.731, F1 = 0.838\n","Epoch 77 : Train - Loss = 5.298 / Val - Loss = 29.320, Acc = 0.941, Precision = 1.000, Recall = 0.386, F1 = 0.557\n","Epoch 78 : Train - Loss = 5.083 / Val - Loss = 8.863, Acc = 0.963, Precision = 0.991, Recall = 0.623, F1 = 0.765\n","Epoch 79 : Train - Loss = 4.583 / Val - Loss = 36.425, Acc = 0.937, Precision = 1.000, Recall = 0.342, F1 = 0.510\n","Epoch 80 : Train - Loss = 5.383 / Val - Loss = 14.691, Acc = 0.954, Precision = 1.000, Recall = 0.520, F1 = 0.685\n","Epoch 81 : Train - Loss = 4.220 / Val - Loss = 33.104, Acc = 0.941, Precision = 1.000, Recall = 0.380, F1 = 0.551\n","Epoch 82 : Train - Loss = 5.488 / Val - Loss = 9.060, Acc = 0.963, Precision = 0.991, Recall = 0.623, F1 = 0.765\n","Epoch 83 : Train - Loss = 4.583 / Val - Loss = 4.607, Acc = 0.969, Precision = 0.987, Recall = 0.687, F1 = 0.810\n","Epoch 84 : Train - Loss = 5.075 / Val - Loss = 6.443, Acc = 0.965, Precision = 0.991, Recall = 0.643, F1 = 0.780\n","Epoch 85 : Train - Loss = 6.560 / Val - Loss = 5.134, Acc = 0.974, Precision = 0.946, Recall = 0.775, F1 = 0.852\n","Epoch 86 : Train - Loss = 4.822 / Val - Loss = 37.571, Acc = 0.935, Precision = 1.000, Recall = 0.325, F1 = 0.490\n","Epoch 87 : Train - Loss = 5.144 / Val - Loss = 4.337, Acc = 0.971, Precision = 0.988, Recall = 0.702, F1 = 0.821\n","Epoch 88 : Train - Loss = 5.674 / Val - Loss = 36.459, Acc = 0.937, Precision = 1.000, Recall = 0.339, F1 = 0.507\n","Epoch 89 : Train - Loss = 5.150 / Val - Loss = 5.960, Acc = 0.968, Precision = 0.991, Recall = 0.670, F1 = 0.799\n","Epoch 90 : Train - Loss = 5.741 / Val - Loss = 33.001, Acc = 0.939, Precision = 1.000, Recall = 0.365, F1 = 0.535\n","Epoch 91 : Train - Loss = 4.783 / Val - Loss = 34.380, Acc = 0.939, Precision = 1.000, Recall = 0.363, F1 = 0.532\n","Epoch 92 : Train - Loss = 4.476 / Val - Loss = 1.971, Acc = 0.971, Precision = 0.848, Recall = 0.851, F1 = 0.850\n","Epoch 93 : Train - Loss = 5.715 / Val - Loss = 2.181, Acc = 0.976, Precision = 0.944, Recall = 0.795, F1 = 0.863\n","Epoch 94 : Train - Loss = 5.848 / Val - Loss = 33.362, Acc = 0.939, Precision = 1.000, Recall = 0.360, F1 = 0.529\n","Epoch 95 : Train - Loss = 4.240 / Val - Loss = 2.023, Acc = 0.975, Precision = 0.899, Recall = 0.830, F1 = 0.863\n","Epoch 96 : Train - Loss = 5.540 / Val - Loss = 24.930, Acc = 0.943, Precision = 1.000, Recall = 0.404, F1 = 0.575\n","Epoch 97 : Train - Loss = 4.901 / Val - Loss = 33.383, Acc = 0.940, Precision = 1.000, Recall = 0.374, F1 = 0.545\n","Epoch 98 : Train - Loss = 5.190 / Val - Loss = 8.775, Acc = 0.964, Precision = 0.991, Recall = 0.626, F1 = 0.767\n","Epoch 99 : Train - Loss = 4.572 / Val - Loss = 3.999, Acc = 0.972, Precision = 0.984, Recall = 0.716, F1 = 0.829\n","Epoch 100 : Train - Loss = 5.860 / Val - Loss = 29.709, Acc = 0.941, Precision = 1.000, Recall = 0.386, F1 = 0.557\n","\n"," ================================================== Final Test ==================================================\n","\n","Test Acc = 0.946, Precision = 0.991, Recall = 0.356, F1 = 0.524\n","\n","Loss = 25.632\n"],"name":"stdout"}]}]}